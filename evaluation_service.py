import os
import re
import httpx
from config import OLLAMA_BASE_URL, LLM_MODEL, EMBEDDING_MODELS, llm_options

PROMPT_FILE = "evaluation_prompt.txt"

DEFAULT_EVALUATION_PROMPT = """à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¸£à¸°à¸šà¸š RAG (Retrieval-Augmented Generation)

**à¸„à¸³à¸–à¸²à¸¡:**
{question}

**à¹€à¸‰à¸¥à¸¢ (Golden Answer) â€” à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™à¹€à¸à¸“à¸‘à¹Œà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸:**
{golden_answer}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding 0.6B:**
{answer_06b}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding 4B:**
{answer_4b}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding 8B:**
{answer_8b}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding BGE-M3:**
{answer_bgem3}

---

## à¸«à¸¥à¸±à¸à¸à¸²à¸£à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™ (à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸ â€” à¸­à¹ˆà¸²à¸™à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸à¹ˆà¸­à¸™à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™)

à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™à¹‚à¸”à¸¢à¹€à¸™à¹‰à¸™à¸—à¸µà¹ˆ **à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸** à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸·à¸­à¸™à¸„à¸³à¸•à¹ˆà¸­à¸„à¸³à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢ à¹€à¸žà¸£à¸²à¸°à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¸”à¸µà¸­à¸²à¸ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸™à¸§à¸™à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¹à¸•à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™

- **à¸„à¸°à¹à¸™à¸™à¸ªà¸¹à¸‡ (70â€“100)**: à¸„à¸³à¸•à¸­à¸šà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡à¹€à¸‰à¸¥à¸¢à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ à¹à¸¡à¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸–à¹‰à¸­à¸¢à¸„à¸³à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™ à¸­à¸™à¸¸à¹‚à¸¥à¸¡à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸šà¹€à¸£à¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ à¸•à¸£à¸²à¸šà¸—à¸µà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹à¸¥à¸°à¸„à¸£à¸š
- **à¸„à¸°à¹à¸™à¸™à¸à¸¥à¸²à¸‡ (40â€“69)**: à¸„à¸³à¸•à¸­à¸šà¸¡à¸µà¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™ à¸«à¸£à¸·à¸­à¸‚à¸²à¸”à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ªà¸³à¸„à¸±à¸à¸šà¸²à¸‡à¸ˆà¸¸à¸”
- **à¸„à¸°à¹à¸™à¸™à¸•à¹ˆà¸³ (0â€“39)**: à¸„à¸³à¸•à¸­à¸šà¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸«à¸¥à¸±à¸ à¸«à¸£à¸·à¸­à¸‚à¸²à¸”à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸«à¸¥à¸±à¸à¹„à¸›

à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸›à¸£à¸°à¹€à¸¡à¸´à¸™:
1. **à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸à¹ƒà¸™à¹€à¸‰à¸¥à¸¢à¸›à¸£à¸²à¸à¸à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸„à¸³à¸•à¸­à¸šà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¸³à¸•à¹ˆà¸­à¸„à¸³)
2. **à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸²à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸•à¸²à¸¡à¸‚à¹‰à¸­à¹€à¸—à¹‡à¸ˆà¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
3. **à¸„à¸§à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡**: à¸„à¸³à¸•à¸­à¸šà¸•à¸­à¸šà¸•à¸£à¸‡à¸„à¸³à¸–à¸²à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

---

## à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸•à¸­à¸š (à¸•à¹‰à¸­à¸‡à¸—à¸³à¸•à¸²à¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸„à¸£à¹ˆà¸‡à¸„à¸£à¸±à¸”)

à¸•à¸­à¸šà¹ƒà¸™à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¸«à¸£à¸·à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:

## à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ

### à¹‚à¸¡à¹€à¸”à¸¥ 0.6B
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¹‚à¸¡à¹€à¸”à¸¥ 4B
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¹‚à¸¡à¹€à¸”à¸¥ 8B
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¹‚à¸¡à¹€à¸”à¸¥ BGE-M3
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¸ªà¸£à¸¸à¸›
[à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸”à¹ƒà¸«à¹‰à¸„à¸³à¸•à¸­à¸šà¸”à¸µà¸à¸§à¹ˆà¸²à¹à¸¥à¸°à¹€à¸žà¸£à¸²à¸°à¹€à¸«à¸•à¸¸à¹ƒà¸”]

---SCORES---
SCORE_06B: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 75 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]
SCORE_4B: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 80 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]
SCORE_8B: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 90 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]
SCORE_BGEM3: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 85 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]

à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸šà¸£à¸£à¸—à¸±à¸” SCORE_* à¸•à¹‰à¸­à¸‡à¸­à¸¢à¸¹à¹ˆà¸«à¸¥à¸±à¸‡ ---SCORES--- à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¸£à¸°à¸šà¸¸à¸„à¸°à¹à¸™à¸™à¹ƒà¸™à¸ªà¹ˆà¸§à¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ"""

# Required placeholders for prompt validation
REQUIRED_PLACEHOLDERS = ["{question}", "{golden_answer}", "{answer_06b}", "{answer_4b}", "{answer_8b}", "{answer_bgem3}"]

# Score labels to extract per model key
_SCORE_LABELS = {key: f"SCORE_{key.upper()}" for key, _, _ in EMBEDDING_MODELS}


def get_evaluation_prompt() -> str:
    """Load evaluation prompt template from file if exists, otherwise return default."""
    try:
        if os.path.exists(PROMPT_FILE):
            with open(PROMPT_FILE, "r", encoding="utf-8") as f:
                return f.read()
    except Exception:
        pass
    return DEFAULT_EVALUATION_PROMPT


def evaluate_answer(
    question: str,
    golden_answer: str,
    answers_by_model: dict,   # {model_key: answer_text}
) -> dict:
    """
    Send all model answers + golden answer to LLM for comparative evaluation.
    Returns {evaluation_text, score_06b, score_4b, score_8b, score_bgem3}.
    """
    prompt_template = get_evaluation_prompt()

    # Build format kwargs â€” fall back to "(à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š)" for missing models
    fmt_kwargs = {
        "question":      question,
        "golden_answer": golden_answer,
        "answer_06b":    answers_by_model.get("06b",   "(à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š)"),
        "answer_4b":     answers_by_model.get("4b",    "(à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š)"),
        "answer_8b":     answers_by_model.get("8b",    "(à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š)"),
        "answer_bgem3":  answers_by_model.get("bgem3", "(à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š)"),
    }

    try:
        prompt = prompt_template.format(**fmt_kwargs)
    except KeyError:
        # Custom prompt may have fewer placeholders â€” format what we can
        from string import Formatter
        used_keys = {fname for _, fname, _, _ in Formatter().parse(prompt_template) if fname}
        prompt = prompt_template.format(**{k: v for k, v in fmt_kwargs.items() if k in used_keys})

    print(f"\n{'â”€'*60}")
    print(f"ðŸ“ [Evaluation Prompt] â†’ {LLM_MODEL}")
    print(prompt)
    print(f"{'â”€'*60}\n")

    payload = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": llm_options(),
    }

    with httpx.Client(timeout=600.0) as client:
        response = client.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json=payload,
        )
        response.raise_for_status()
        result = response.json()
        evaluation_text = result.get("response", "").strip()
    print(f"ðŸ’¬ [Eval response preview]: {evaluation_text[:300]}\n")

    # Parse scores for all models
    scores = {key: _extract_score(evaluation_text, label) for key, label in _SCORE_LABELS.items()}

    return {"evaluation_text": evaluation_text, **{f"score_{k}": v for k, v in scores.items()}}


def _extract_score(text: str, label: str) -> float:
    """Extract numeric score from evaluation text."""
    try:
        for line in text.split("\n"):
            if label in line:
                clean_line = line.replace("**", "").replace("*", "")
                parts = clean_line.split(label)
                if len(parts) > 1:
                    num_str = parts[1].strip().strip(":").strip()
                    match = re.search(r'\d+(?:\.\d+)?', num_str)
                    if match:
                        return float(match.group())
    except Exception:
        pass
    return 0.0


def evaluate_all(rag_results: list[dict]) -> list[dict]:
    """
    Evaluate all RAG results against golden answers.

    Each item in rag_results must have:
        question_number, question_text, golden_answer, answers_by_model
    """
    evaluations = []
    for r in rag_results:
        q_num = r["question_number"]
        print(f"  ðŸ“Š Evaluating question {q_num}...")

        eval_result = evaluate_answer(
            question=r["question_text"],
            golden_answer=r["golden_answer"],
            answers_by_model=r["answers_by_model"],
        )

        evaluations.append({
            "question_number":  q_num,
            "question_text":    r["question_text"],
            "golden_answer":    r["golden_answer"],
            "answers_by_model": r["answers_by_model"],
            **eval_result,
        })

    return evaluations
