import os
import httpx
from config import OLLAMA_BASE_URL, LLM_MODEL, llm_options

PROMPT_FILE = "evaluation_prompt.txt"

DEFAULT_EVALUATION_PROMPT = """à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¸£à¸°à¸šà¸š RAG (Retrieval-Augmented Generation)

**à¸„à¸³à¸–à¸²à¸¡:**
{question}

**à¹€à¸‰à¸¥à¸¢ (Golden Answer) â€” à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™à¹€à¸à¸“à¸‘à¹Œà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸:**
{golden_answer}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding 4B:**
{answer_4b}

**à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ Embedding 8B:**
{answer_8b}

---

## à¸«à¸¥à¸±à¸à¸à¸²à¸£à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™ (à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸ â€” à¸­à¹ˆà¸²à¸™à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸à¹ˆà¸­à¸™à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™)

à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™à¹‚à¸”à¸¢à¹€à¸™à¹‰à¸™à¸—à¸µà¹ˆ **à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸** à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸·à¸­à¸™à¸„à¸³à¸•à¹ˆà¸­à¸„à¸³à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢ à¹€à¸žà¸£à¸²à¸°à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¸”à¸µà¸­à¸²à¸ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸™à¸§à¸™à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¹à¸•à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™

- **à¸„à¸°à¹à¸™à¸™à¸ªà¸¹à¸‡ (70â€“100)**: à¸„à¸³à¸•à¸­à¸šà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡à¹€à¸‰à¸¥à¸¢à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ à¹à¸¡à¹‰à¸ˆà¸°à¹ƒà¸Šà¹‰à¸–à¹‰à¸­à¸¢à¸„à¸³à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™ à¸­à¸™à¸¸à¹‚à¸¥à¸¡à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸šà¹€à¸£à¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ à¸•à¸£à¸²à¸šà¸—à¸µà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹à¸¥à¸°à¸„à¸£à¸š
- **à¸„à¸°à¹à¸™à¸™à¸à¸¥à¸²à¸‡ (40â€“69)**: à¸„à¸³à¸•à¸­à¸šà¸¡à¸µà¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™ à¸«à¸£à¸·à¸­à¸‚à¸²à¸”à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ªà¸³à¸„à¸±à¸à¸šà¸²à¸‡à¸ˆà¸¸à¸”
- **à¸„à¸°à¹à¸™à¸™à¸•à¹ˆà¸³ (0â€“39)**: à¸„à¸³à¸•à¸­à¸šà¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸«à¸¥à¸±à¸ à¸«à¸£à¸·à¸­à¸‚à¸²à¸”à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸«à¸¥à¸±à¸à¹„à¸›

à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸›à¸£à¸°à¹€à¸¡à¸´à¸™:
1. **à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸à¹ƒà¸™à¹€à¸‰à¸¥à¸¢à¸›à¸£à¸²à¸à¸à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸„à¸³à¸•à¸­à¸šà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸„à¸³à¸•à¹ˆà¸­à¸„à¸³)
2. **à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡**: à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸²à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸•à¸²à¸¡à¸‚à¹‰à¸­à¹€à¸—à¹‡à¸ˆà¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
3. **à¸„à¸§à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡**: à¸„à¸³à¸•à¸­à¸šà¸•à¸­à¸šà¸•à¸£à¸‡à¸„à¸³à¸–à¸²à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

---

## à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸•à¸­à¸š (à¸•à¹‰à¸­à¸‡à¸—à¸³à¸•à¸²à¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸„à¸£à¹ˆà¸‡à¸„à¸£à¸±à¸”)

à¸•à¸­à¸šà¹ƒà¸™à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¸«à¸£à¸·à¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡:

## à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ

### à¹‚à¸¡à¹€à¸”à¸¥ 4B
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¹‚à¸¡à¹€à¸”à¸¥ 8B
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸„à¸£à¸š: [à¸£à¸°à¸šà¸¸à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‰à¸¥à¸¢]
- à¹ƒà¸ˆà¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸²à¸”/à¸œà¸´à¸”: [à¸£à¸°à¸šà¸¸à¸–à¹‰à¸²à¸¡à¸µ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸ "à¹„à¸¡à¹ˆà¸¡à¸µ"]

### à¸ªà¸£à¸¸à¸›
[à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥à¹ƒà¸”à¹ƒà¸«à¹‰à¸„à¸³à¸•à¸­à¸šà¸”à¸µà¸à¸§à¹ˆà¸²à¹à¸¥à¸°à¹€à¸žà¸£à¸²à¸°à¹€à¸«à¸•à¸¸à¹ƒà¸”]

---SCORES---
SCORE_4B: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 75 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]
SCORE_8B: [à¸•à¸±à¸§à¹€à¸¥à¸‚à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ 90 à¸«à¹‰à¸²à¸¡à¹ƒà¸ªà¹ˆ ** à¸«à¸£à¸·à¸­ text à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰]

à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸šà¸£à¸£à¸—à¸±à¸” SCORE_4B à¹à¸¥à¸° SCORE_8B à¸•à¹‰à¸­à¸‡à¸­à¸¢à¸¹à¹ˆà¸«à¸¥à¸±à¸‡ ---SCORES--- à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¸£à¸°à¸šà¸¸à¸„à¸°à¹à¸™à¸™à¹ƒà¸™à¸ªà¹ˆà¸§à¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ"""


def get_evaluation_prompt() -> str:
    """Load evaluation prompt template from file if exists, otherwise return default."""
    try:
        if os.path.exists(PROMPT_FILE):
            with open(PROMPT_FILE, "r", encoding="utf-8") as f:
                return f.read()
    except Exception:
        pass
    return DEFAULT_EVALUATION_PROMPT


def evaluate_answer(
    question: str,
    golden_answer: str,
    answer_4b: str,
    answer_8b: str,
) -> dict:
    """
    Send both model answers + golden answer to LLM for comparative evaluation.
    Returns {evaluation_text, score_4b, score_8b}.
    """
    prompt_template = get_evaluation_prompt()
    prompt = prompt_template.format(
        question=question,
        golden_answer=golden_answer,
        answer_4b=answer_4b,
        answer_8b=answer_8b,
    )

    print(f"\n{'â”€'*60}")
    print(f"ðŸ“ [Evaluation Prompt] â†’ {LLM_MODEL}")
    print(prompt)
    print(f"{'â”€'*60}\n")

    payload = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": llm_options(),
    }

    with httpx.Client(timeout=600.0) as client:
        response = client.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json=payload,
        )
        response.raise_for_status()
        result = response.json()
        evaluation_text = result.get("response", "").strip()
    print(f"ðŸ’¬ [Eval response preview]: {evaluation_text[:300]}\n")

    # Try to parse scores from evaluation text
    score_4b = _extract_score(evaluation_text, "SCORE_4B")
    score_8b = _extract_score(evaluation_text, "SCORE_8B")

    return {
        "evaluation_text": evaluation_text,
        "score_4b": score_4b,
        "score_8b": score_8b,
    }


def _extract_score(text: str, label: str) -> float:
    """Extract numeric score from evaluation text."""
    import re
    try:
        for line in text.split("\n"):
            if label in line:
                # Strip markdown bold/italic markers before parsing (keep _ to preserve label)
                clean_line = line.replace("**", "").replace("*", "")
                parts = clean_line.split(label)
                if len(parts) > 1:
                    num_str = parts[1].strip().strip(":").strip()
                    # Get first number-like token (integer or decimal)
                    match = re.search(r'\d+(?:\.\d+)?', num_str)
                    if match:
                        return float(match.group())
    except Exception:
        pass
    return 0.0


def evaluate_all(rag_results: list[dict]) -> list[dict]:
    """Evaluate all RAG results against golden answers."""
    evaluations = []
    for r in rag_results:
        q_num = r["question_number"]
        print(f"  ðŸ“Š Evaluating question {q_num}...")

        eval_result = evaluate_answer(
            question=r["question_text"],
            golden_answer=r["golden_answer"],
            answer_4b=r["result_4b"]["llm_answer"],
            answer_8b=r["result_8b"]["llm_answer"],
        )

        evaluations.append({
            "question_number": q_num,
            "question_text": r["question_text"],
            "golden_answer": r["golden_answer"],
            "answer_4b": r["result_4b"]["llm_answer"],
            "answer_8b": r["result_8b"]["llm_answer"],
            **eval_result,
        })

    return evaluations
